{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "2    1\n",
      "3    2\n",
      "4    1\n",
      "Name: country_destination, dtype: int64\n",
      "   timestamp_first_active    gender       age  signup_method  signup_flow  \\\n",
      "0               -4.380020 -0.927300 -0.163283      -1.596552    -0.427798   \n",
      "1               -4.357961  1.058047  0.287705      -1.596552    -0.427798   \n",
      "2               -4.348661 -0.927300  2.317149       0.628333    -0.035009   \n",
      "3               -4.303076 -0.927300  0.738692      -1.596552    -0.427798   \n",
      "4               -4.283949 -0.927300  0.625945       0.628333    -0.427798   \n",
      "\n",
      "   language  affiliate_channel  affiliate_provider  first_affiliate_tracked  \\\n",
      "0 -0.141579          -0.582242           -0.468760                -0.798954   \n",
      "1 -0.141579           2.556797            0.251719                -0.798954   \n",
      "2 -0.141579          -0.582242           -0.468760                -0.798954   \n",
      "3 -0.141579          -0.582242           -0.468760                -0.798954   \n",
      "4 -0.141579          -0.582242           -0.468760                -0.798954   \n",
      "\n",
      "   signup_app      ...       Linux Desktop  Mac Desktop  Opera Phone  \\\n",
      "0   -0.359375      ...           -0.120933    -0.220553    -0.726855   \n",
      "1   -0.359375      ...           -0.120933    -0.220553    -0.726855   \n",
      "2   -0.359375      ...           -0.120933    -0.220553    -0.726855   \n",
      "3   -0.359375      ...           -0.120933    -0.220553    -0.726855   \n",
      "4   -0.359375      ...           -0.120933    -0.220553    -0.726855   \n",
      "\n",
      "     Tablet  Windows Desktop  Windows Phone  iPad Tablet    iPhone  iPodtouch  \\\n",
      "0 -0.062776        -0.196923      -0.707107    -0.108443 -0.133838  -0.153578   \n",
      "1 -0.062776        -0.196923      -0.707107    -0.108443 -0.133838  -0.153578   \n",
      "2 -0.062776        -0.196923      -0.707107    -0.108443 -0.133838  -0.153578   \n",
      "3 -0.062776        -0.196923      -0.707107    -0.108443 -0.133838  -0.153578   \n",
      "4 -0.062776        -0.196923      -0.707107    -0.108443 -0.133838  -0.153578   \n",
      "\n",
      "   secs_elapsed  \n",
      "0     -0.391996  \n",
      "1     -0.391996  \n",
      "2     -0.391996  \n",
      "3     -0.391996  \n",
      "4     -0.391996  \n",
      "\n",
      "[5 rows x 41 columns]\n",
      "Index(['timestamp_first_active', 'gender', 'age', 'signup_method',\n",
      "       'signup_flow', 'language', 'affiliate_channel', 'affiliate_provider',\n",
      "       'first_affiliate_tracked', 'signup_app', 'first_device_type',\n",
      "       'first_browser', 'created_year', 'created_month', 'created_day',\n",
      "       'session_count', '-unknown-_x', 'booking_request', 'booking_response',\n",
      "       'click', 'data', 'message_post', 'modify', 'partner_callback', 'submit',\n",
      "       'view', '-unknown-_y', 'Android App Unknown Phone/Tablet',\n",
      "       'Android Phone', 'Blackberry', 'Chromebook', 'Linux Desktop',\n",
      "       'Mac Desktop', 'Opera Phone', 'Tablet', 'Windows Desktop',\n",
      "       'Windows Phone', 'iPad Tablet', 'iPhone', 'iPodtouch', 'secs_elapsed'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Read the train and the test data \n",
    "train_users = pd.read_csv('train_users_merge_scale.csv')\n",
    "#test_users = pd.read_csv('test_users.csv')\n",
    "\n",
    "\n",
    "# Extracting labels from the train data\n",
    "train_users_labels = train_users.loc[:,'country_destination']\n",
    "print (train_users_labels.head(n=5))\n",
    "\n",
    "# Extracting attributes from the train data\n",
    "train_users_attrs = train_users.iloc[:,:-1]\n",
    "print(train_users_attrs.head(n=5))\n",
    "\n",
    "train_users = train_users_attrs\n",
    "print(train_users.columns)\n",
    "train_users = train_users.drop(['Blackberry'], axis=1)\n",
    "train_users = train_users.drop(['Opera Phone'], axis=1)\n",
    "labels_df = pd.DataFrame(train_users_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def dcg_score(y_true, y_score, k=5):\n",
    "\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order[:k])\n",
    "\n",
    "    gain = 2 ** y_true - 1\n",
    "\n",
    "    discounts = np.log2(np.arange(len(y_true)) + 2)\n",
    "    return np.sum(gain / discounts)\n",
    "\n",
    "\n",
    "#def ndcg_score(ground_truth, predictions, k=5):\n",
    "def ndcg_score(te_labels, predict, k):\n",
    "   \n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(range(12 + 1))\n",
    "    T = lb.transform(te_labels)\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    # Iterate over each y_true and compute the DCG score\n",
    "    for y_true, y_score in zip(T, predict):\n",
    "        actual = dcg_score(y_true, y_score, k)\n",
    "        best = dcg_score(y_true, y_true, k)\n",
    "        if best == 0:\n",
    "            best = 0.000000001\n",
    "        score = float(actual) / float(best)\n",
    "        scores.append(score)\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "# NDCG Scorer function\n",
    "ndcg_scorer = make_scorer(ndcg_score, needs_proba=True, k=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def folds_to_split(data,targets,train,test):\n",
    "    data_tr = pd.DataFrame(data).iloc[train]\n",
    "    data_te = pd.DataFrame(data).iloc[test]\n",
    "    labels_tr = pd.DataFrame(targets).iloc[train]\n",
    "    labels_te = pd.DataFrame(targets).iloc[test]\n",
    "    return [data_tr, data_te, labels_tr, labels_te]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------OneVsRestClassifier accuracy and ndcg values------\n",
      "    Accuracy_newton-cg  ndcg_newton-cg  Accuracy_lbfgs  ndcg_lbfgs  \\\n",
      "1             0.607278        0.815000        0.607278    0.815000   \n",
      "2             0.603587        0.813433        0.603587    0.813436   \n",
      "3             0.604344        0.812489        0.604344    0.812489   \n",
      "4             0.602073        0.812163        0.602073    0.812145   \n",
      "5             0.604581        0.813422        0.604581    0.813422   \n",
      "6             0.613099        0.817676        0.613099    0.817676   \n",
      "7             0.610212        0.816933        0.610212    0.816914   \n",
      "8             0.610117        0.816962        0.610117    0.816962   \n",
      "9             0.608272        0.815800        0.608272    0.815800   \n",
      "10            0.608461        0.816193        0.608461    0.816191   \n",
      "\n",
      "    Accuracy_liblinear  ndcg_liblinear  \n",
      "1             0.607278        0.815000  \n",
      "2             0.603587        0.813433  \n",
      "3             0.604344        0.812489  \n",
      "4             0.602073        0.812163  \n",
      "5             0.604581        0.813422  \n",
      "6             0.613099        0.817676  \n",
      "7             0.610212        0.816933  \n",
      "8             0.610165        0.816979  \n",
      "9             0.608272        0.815819  \n",
      "10            0.608461        0.816193  \n",
      "------OneVsRestClassifier mean accuracy, ndcg values------\n",
      "Accuracy_newton-cg    0.607202\n",
      "ndcg_newton-cg        0.815007\n",
      "Accuracy_lbfgs        0.607202\n",
      "ndcg_lbfgs            0.815004\n",
      "Accuracy_liblinear    0.607207\n",
      "ndcg_liblinear        0.815011\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression : One Versus Rest\n",
    "# Use validation set to find which solver to use \n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import linear_model, cross_validation\n",
    "\n",
    "fold_results_ovr = pd.DataFrame()\n",
    "test_sets = []\n",
    "test_set_labels = []\n",
    "train_sets = []\n",
    "train_set_labels = []\n",
    "    \n",
    "def ten_fold_oneVsRest(data, labels):\n",
    "    \n",
    "    for train, test in cross_validation.KFold(len(data), n_folds=10, shuffle=True, random_state=20160202):\n",
    "        [tr_data, te_data,\n",
    "         tr_target, te_target] = folds_to_split(data, labels,train,test)\n",
    "        \n",
    "        train_sets.append(tr_data)\n",
    "        train_set_labels.append(tr_target)\n",
    "        test_sets.append(te_data)\n",
    "        test_set_labels.append(te_target)\n",
    "        \n",
    "    foldnum = 0\n",
    "    solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "    for x in range(0, 10):\n",
    "        foldnum+=1\n",
    "        [bnb_train, bnb_validation, bnb_train_labels, bnb_validation_labels] = cross_validation.train_test_split(\n",
    "        train_sets[x], \n",
    "        train_set_labels[x], \n",
    "        test_size=0.11, \n",
    "        random_state=20160121)\n",
    "        \n",
    "        for sol in solvers:\n",
    "            oneVsRest = OneVsRestClassifier(linear_model.LogisticRegression(solver=sol))\n",
    "            #print(tr_target)\n",
    "            oneVsRest.fit(bnb_train.values, bnb_train_labels[bnb_train_labels.columns.values[0]].values)\n",
    "            #print(oneVsRest.estimators_)\n",
    "        \n",
    "            fold_results_ovr.loc[foldnum, 'Accuracy_' + sol] = oneVsRest.score(bnb_validation, bnb_validation_labels)\n",
    "        \n",
    "            predictions = oneVsRest.predict_proba(bnb_validation)\n",
    "            score = ndcg_score(bnb_validation_labels.as_matrix(), predictions, 5)\n",
    "            fold_results_ovr.loc[foldnum, 'ndcg_' + sol]  = score\n",
    "            #print(score)\n",
    "                \n",
    "    #Now let's look at the results:\n",
    "    print (\"------OneVsRestClassifier accuracy and ndcg values------\")\n",
    "    print (fold_results_ovr)\n",
    "    print (\"------OneVsRestClassifier mean accuracy, ndcg values------\")\n",
    "    print(fold_results_ovr.mean())\n",
    "    \n",
    "ten_fold_oneVsRest(train_users, labels_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------OneVsRestClassifier accuracy and ndcg values------\n",
      "    Accuracy      ndcg\n",
      "1   0.608076  0.816181\n",
      "2   0.609885  0.816683\n",
      "3   0.604685  0.813442\n",
      "4   0.606840  0.815432\n",
      "5   0.606606  0.815835\n",
      "6   0.604872  0.814452\n",
      "7   0.607121  0.813901\n",
      "8   0.602670  0.813187\n",
      "9   0.610588  0.818077\n",
      "10  0.611525  0.816938\n",
      "------OneVsRestClassifier mean accuracy, ndcg values------\n",
      "Accuracy    0.607287\n",
      "ndcg        0.815413\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "fold_results_ovr = pd.DataFrame()\n",
    "foldnum = 0\n",
    "for x in range(0, 10):\n",
    "    foldnum+=1\n",
    "    oneVsRest = OneVsRestClassifier(linear_model.LogisticRegression(solver='lbfgs', penalty='l2'))\n",
    "    oneVsRest.fit(train_sets[x].values, train_set_labels[x].values.ravel())\n",
    "    \n",
    "    fold_results_ovr.loc[foldnum, 'Accuracy'] = oneVsOne.score(test_sets[x].values,\n",
    "                                                          test_set_labels[x].values.ravel())\n",
    "    \n",
    "    predictions = oneVsRest.predict_proba(test_sets[x].values)\n",
    "    score = ndcg_score(test_set_labels[x].as_matrix(), predictions, 5)\n",
    "    fold_results_ovr.loc[foldnum, 'ndcg']  = score\n",
    "    \n",
    "print (\"------OneVsRestClassifier accuracy and ndcg values------\")\n",
    "print (fold_results_ovr)\n",
    "print (\"------OneVsRestClassifier mean accuracy, ndcg values------\")\n",
    "print(fold_results_ovr.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------OneVsRestClassifier accuracy and ndcg values------\n",
      "    Accuracy      ndcg\n",
      "1   0.608076  0.816163\n",
      "2   0.609885  0.816683\n",
      "3   0.604685  0.813442\n",
      "4   0.606840  0.815413\n",
      "5   0.606606  0.815870\n",
      "6   0.604872  0.814452\n",
      "7   0.607121  0.813901\n",
      "8   0.602670  0.813169\n",
      "9   0.610588  0.818077\n",
      "10  0.611525  0.816955\n",
      "------OneVsRestClassifier mean accuracy, ndcg values------\n",
      "Accuracy    0.607287\n",
      "ndcg        0.815412\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# liblinear and lbfgs perform  nearly the same...\n",
    "\n",
    "fold_results_ovr = pd.DataFrame()\n",
    "foldnum = 0\n",
    "for x in range(0, 10):\n",
    "    foldnum+=1\n",
    "    oneVsRest = OneVsRestClassifier(linear_model.LogisticRegression(solver='liblinear', penalty='l2'))\n",
    "    oneVsRest.fit(train_sets[x].values, train_set_labels[x].values.ravel())\n",
    "    \n",
    "    fold_results_ovr.loc[foldnum, 'Accuracy'] = oneVsOne.score(test_sets[x].values,\n",
    "                                                          test_set_labels[x].values.ravel())\n",
    "    \n",
    "    predictions = oneVsRest.predict_proba(test_sets[x].values)\n",
    "    score = ndcg_score(test_set_labels[x].as_matrix(), predictions, 5)\n",
    "    fold_results_ovr.loc[foldnum, 'ndcg']  = score\n",
    "    \n",
    "print (\"------OneVsRestClassifier accuracy and ndcg values------\")\n",
    "print (fold_results_ovr)\n",
    "print (\"------OneVsRestClassifier mean accuracy, ndcg values------\")\n",
    "print(fold_results_ovr.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------OneVsRestClassifier accuracy and ndcg values------\n",
      "    Accuracy      ndcg\n",
      "1   0.608076  0.816199\n",
      "2   0.609885  0.816708\n",
      "3   0.604685  0.813442\n",
      "4   0.606840  0.815416\n",
      "5   0.606606  0.815858\n",
      "6   0.604872  0.814483\n",
      "7   0.607121  0.813844\n",
      "8   0.602670  0.813170\n",
      "9   0.610588  0.818057\n",
      "10  0.611525  0.816993\n",
      "------OneVsRestClassifier mean accuracy, ndcg values------\n",
      "Accuracy    0.607287\n",
      "ndcg        0.815417\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# liblinear does better with l1 penalty...\n",
    "\n",
    "fold_results_ovr = pd.DataFrame()\n",
    "foldnum = 0\n",
    "for x in range(0, 10):\n",
    "    foldnum+=1\n",
    "    oneVsRest = OneVsRestClassifier(linear_model.LogisticRegression(solver='liblinear', penalty='l1'))\n",
    "    oneVsRest.fit(train_sets[x].values, train_set_labels[x].values.ravel())\n",
    "    \n",
    "    fold_results_ovr.loc[foldnum, 'Accuracy'] = oneVsOne.score(test_sets[x].values,\n",
    "                                                          test_set_labels[x].values.ravel())\n",
    "    \n",
    "    predictions = oneVsRest.predict_proba(test_sets[x].values)\n",
    "    score = ndcg_score(test_set_labels[x].as_matrix(), predictions, 5)\n",
    "    fold_results_ovr.loc[foldnum, 'ndcg']  = score\n",
    "    \n",
    "print (\"------OneVsRestClassifier accuracy and ndcg values------\")\n",
    "print (fold_results_ovr)\n",
    "print (\"------OneVsRestClassifier mean accuracy, ndcg values------\")\n",
    "print(fold_results_ovr.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------OneVsOneClassifier results for accuracy-----------\n",
      "    Accuracy_newton-cg  Accuracy_lbfgs  Accuracy_liblinear\n",
      "1             0.604770        0.604770            0.604770\n",
      "2             0.609218        0.609218            0.609218\n",
      "3             0.608556        0.608556            0.608556\n",
      "4             0.605622        0.605622            0.605622\n",
      "5             0.612152        0.612152            0.612152\n",
      "6             0.605338        0.605338            0.605338\n",
      "7             0.602499        0.602499            0.602499\n",
      "8             0.610969        0.611016            0.610969\n",
      "9             0.608840        0.608840            0.608840\n",
      "10            0.605858        0.605858            0.605858\n",
      "--------------OneVsOneClassifier mean accuracy----------------\n",
      "Accuracy_newton-cg    0.607382\n",
      "Accuracy_lbfgs        0.607387\n",
      "Accuracy_liblinear    0.607382\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sanjana\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:285: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\sanjana\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:193: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression : One Versus One\n",
    "# Use validation set to find which solver to use \n",
    "\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "fold_results_ovo = pd.DataFrame()\n",
    "test_sets = []\n",
    "test_set_labels = []\n",
    "train_sets = []\n",
    "train_set_labels = []\n",
    "\n",
    "def ten_fold_oneVsOne(data, labels):\n",
    "    foldnum = 0\n",
    "    solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "    \n",
    "    for train, test in cross_validation.KFold(len(data), n_folds=10, shuffle=True):\n",
    "        [tr_data, te_data,\n",
    "         tr_target, te_target] = folds_to_split(data, labels,train,test)\n",
    "        \n",
    "        train_sets.append(tr_data)\n",
    "        train_set_labels.append(tr_target)\n",
    "        test_sets.append(te_data)\n",
    "        test_set_labels.append(te_target)\n",
    "    \n",
    "    foldnum = 0\n",
    "    for x in range(0, 10):\n",
    "        foldnum+=1\n",
    "        [bnb_train, bnb_validation, bnb_train_labels, bnb_validation_labels] = cross_validation.train_test_split(\n",
    "        train_sets[x], \n",
    "        train_set_labels[x], \n",
    "        test_size=0.11, \n",
    "        random_state=20160121)\n",
    "        for sol in solvers:\n",
    "            oneVsOne = OneVsOneClassifier(linear_model.LogisticRegression(solver=sol))\n",
    "            oneVsOne.fit(bnb_train.values, bnb_train_labels[bnb_train_labels.columns.values[0]].values)\n",
    "        \n",
    "            columnname = \"Accuracy\" + \"_\" + sol\n",
    "            fold_results_ovo.loc[foldnum, columnname] = oneVsOne.score(bnb_validation, bnb_validation_labels)\n",
    "    \n",
    "    #Now let's look at the results:\n",
    "    print (\"-----------OneVsOneClassifier results for accuracy-----------\")\n",
    "    print (fold_results_ovo)\n",
    "    \n",
    "    print (\"--------------OneVsOneClassifier mean accuracy----------------\")\n",
    "    print(fold_results_ovo.mean())\n",
    "    \n",
    "ten_fold_oneVsOne(train_users, labels_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------OneVsOneClassifier results for accuracy-----------\n",
      "    Accuracy\n",
      "1   0.602080\n",
      "2   0.607309\n",
      "3   0.608855\n",
      "4   0.607871\n",
      "5   0.605247\n",
      "6   0.600609\n",
      "7   0.608199\n",
      "8   0.612087\n",
      "9   0.609932\n",
      "10  0.610354\n",
      "--------------OneVsOneClassifier mean accuracy----------------\n",
      "Accuracy    0.607254\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# lbfgs does best every time...\n",
    "\n",
    "fold_results_ovo = pd.DataFrame()\n",
    "foldnum = 0\n",
    "for x in range(0, 10):\n",
    "    \n",
    "    foldnum+=1\n",
    "    oneVsOne = OneVsOneClassifier(linear_model.LogisticRegression(solver='lbfgs'))\n",
    "    oneVsOne.fit(train_sets[x].values, train_set_labels[x].values.ravel())\n",
    "    \n",
    "    fold_results_ovo.loc[foldnum, 'Accuracy'] = oneVsOne.score(test_sets[x].values,\n",
    "                                                          test_set_labels[x].values.ravel())\n",
    "    \n",
    "\n",
    "print (\"-----------OneVsOneClassifier results for accuracy-----------\")\n",
    "print (fold_results_ovo)\n",
    "print (\"--------------OneVsOneClassifier mean accuracy----------------\")\n",
    "print(fold_results_ovo.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use ADA boost with logistsic regression\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import linear_model, cross_validation\n",
    "\n",
    "test_sets = []\n",
    "test_set_labels = []\n",
    "train_sets = []\n",
    "train_set_labels = []\n",
    "def ten_fold_ada_logistic(data, labels):\n",
    "    foldnum = 0\n",
    "    fold_results_ovr_est = pd.DataFrame()\n",
    "    fold_results_ada = pd.DataFrame()\n",
    "    for train, test in cross_validation.KFold(len(data), n_folds=10, shuffle=True, random_state=20160202):\n",
    "        \n",
    "        [tr_data, te_data,\n",
    "         tr_target, te_target] = folds_to_split(data, labels,train,test)\n",
    "        train_sets.append(tr_data)\n",
    "        train_set_labels.append(tr_target)\n",
    "        test_sets.append(te_data)\n",
    "        test_set_labels.append(te_target)\n",
    "    \n",
    "    solvers = ['newton-cg', 'lbfgs']\n",
    "    estimators = [100, 200, 250]\n",
    "    foldnum = 0\n",
    "    for x in range(0, 10):\n",
    "        foldnum+=1\n",
    "        [bnb_train, bnb_validation, bnb_train_labels, bnb_validation_labels] = cross_validation.train_test_split(\n",
    "            train_sets[x], \n",
    "            train_set_labels[x], \n",
    "            test_size=0.11, \n",
    "            random_state=20160121)\n",
    "        for sol in solvers:\n",
    "            for est in estimators:\n",
    "                \n",
    "                [tr_data, te_data,\n",
    "                 tr_target, te_target] = folds_to_split(data, labels,train,test)\n",
    "                ada = AdaBoostClassifier(learning_rate=0.3, n_estimators=est, \n",
    "                                     base_estimator=linear_model.LogisticRegression(solver=sol), \n",
    "                                     algorithm='SAMME')  \n",
    "                #print(tr_target)\n",
    "                ada.fit(bnb_train.values, bnb_train_labels[bnb_train_labels.columns.values[0]].values)\n",
    "                #print(oneVsRest.estimators_)\n",
    "        \n",
    "                fold_results_ada.loc[foldnum, 'Accuracy_' + sol + '_' + str(est)] = ada.score(bnb_validation, \n",
    "                                                                                            bnb_validation_labels)\n",
    "        \n",
    "                predictions = ada.predict_proba(bnb_validation)\n",
    "                score = ndcg_score(bnb_validation_labels.as_matrix(), predictions, 5)\n",
    "                fold_results_ada.loc[foldnum, 'ndcg_' + sol + '_' + str(est)]  = score\n",
    "                #print(score)\n",
    "            \n",
    "    \n",
    "    #Now let's look at the results:\n",
    "    print (\"------Ada accuracy and ndcg values------\")\n",
    "    print (fold_results_ada)\n",
    "    print (\"------Ada mean accuracy and ndcg values------\")\n",
    "    print(fold_results_ada.mean())\n",
    "    \n",
    "ten_fold_ada_logistic(train_users, labels_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Ada accuracy and ndcg values------\n",
      "    Accuracy      ndcg\n",
      "1   0.598426  0.808153\n",
      "2   0.604825  0.809260\n",
      "3   0.600141  0.805607\n",
      "4   0.601265  0.807822\n",
      "5   0.604170  0.807697\n",
      "6   0.598688  0.806826\n",
      "7   0.605107  0.805142\n",
      "8   0.593769  0.804849\n",
      "9   0.604029  0.810024\n",
      "10  0.604966  0.809372\n",
      "------Ada mean accuracy and ndcg values------\n",
      "Accuracy    0.601539\n",
      "ndcg        0.807475\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# The best value is for newton-cg, estimators: 200\n",
    "\n",
    "fold_results_ada = pd.DataFrame()\n",
    "foldnum = 0\n",
    "for x in range(0, 10):\n",
    "    # one fourth of the training data is for validation\n",
    "    foldnum+=1\n",
    "    ada = AdaBoostClassifier(learning_rate=0.3, n_estimators=200, \n",
    "                                     base_estimator=linear_model.LogisticRegression(solver='newton-cg'), \n",
    "                                     algorithm='SAMME') \n",
    "    \n",
    "    ada.fit(train_sets[x].values, train_set_labels[x].values.ravel())\n",
    "    \n",
    "    fold_results_ada.loc[foldnum, 'Accuracy'] = ada.score(test_sets[x].values,\n",
    "                                                          test_set_labels[x].values.ravel())\n",
    "        \n",
    "    predictions = ada.predict_proba(test_sets[x].values)\n",
    "    score = ndcg_score(test_set_labels[x].as_matrix(), predictions, 5)\n",
    "    fold_results_ada.loc[foldnum, 'ndcg']  = score\n",
    "    \n",
    "\n",
    "print (\"------Ada accuracy and ndcg values------\")\n",
    "print (fold_results_ada)\n",
    "print (\"------Ada mean accuracy and ndcg values------\")\n",
    "print(fold_results_ada.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Not completing even after running for a few hours\n",
    "\n",
    "from sklearn import svm\n",
    "    \n",
    "def ten_fold_svm(data, labels):\n",
    "    foldnum = 0\n",
    "    fold_results_ovr_est = pd.DataFrame()\n",
    "    fold_results_ada = pd.DataFrame()\n",
    "    for train, test in cross_validation.KFold(len(data), n_folds=10, shuffle=True, random_state=20160202):\n",
    "        foldnum+=1\n",
    "        [tr_data, te_data,\n",
    "         tr_target, te_target] = folds_to_split(data, labels,train,test)\n",
    "        vec_mach = svm.SVC(kernel='rbf', random_state=20160202)\n",
    "        #print(tr_target)\n",
    "        vec_mach.fit(tr_data.values, tr_target[tr_target.columns.values[0]].values)\n",
    "        #print(oneVsRest.estimators_)\n",
    "        \n",
    "        #perc.fit(heart_tr_data, heart_tr_target[0].values)\n",
    "        fold_results_ada.loc[foldnum, 'Accuracy'] = vec_mach.score(te_data, te_target)\n",
    "        \n",
    "        predictions = vec_mach.predict_proba(te_data)\n",
    "        score = ndcg_score(te_target.as_matrix(), predictions, 5)\n",
    "        fold_results_ada.loc[foldnum, 'ndcg']  = score\n",
    "        print(score)\n",
    "            \n",
    "    \n",
    "    #Now let's look at the results:\n",
    "    print (\"------svm accuracy values------\")\n",
    "    print (fold_results_ovr)\n",
    "    print (\"------svm mean accuracy values------\")\n",
    "    print(fold_results_ovr.mean())\n",
    "    \n",
    "ten_fold_svm(train_users, labels_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.683457898712\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-bebec4489211>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfold_results_ovo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m \u001b[0mten_fold_oneVsRest_Perc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_users\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-39-bebec4489211>\u001b[0m in \u001b[0;36mten_fold_oneVsRest_Perc\u001b[1;34m(data, labels)\u001b[0m\n\u001b[0;32m     35\u001b[0m                           \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m                           solver='liblinear', tol=0.0001)\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0moneVsOne\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbnb_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbnb_train_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbnb_train_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;31m#perc.fit(heart_tr_data, heart_tr_target[0].values)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\sanjana\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1581\u001b[0m                       \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1582\u001b[0m                       )\n\u001b[1;32m-> 1583\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miter_labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1584\u001b[0m             for train, test in folds)\n\u001b[0;32m   1585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\sanjana\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    802\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    803\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 804\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    805\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\sanjana\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    660\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 662\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    663\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    664\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\sanjana\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateComputeBatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\sanjana\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\sanjana\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\sanjana\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\sanjana\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36m_log_reg_scoring_path\u001b[1;34m(X, y, train, test, pos_class, Cs, scoring, fit_intercept, max_iter, tol, class_weight, verbose, solver, penalty, dual, intercept_scaling, multi_class, random_state, max_squared_sum, sample_weight)\u001b[0m\n\u001b[0;32m    881\u001b[0m         \u001b[0mintercept_scaling\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mintercept_scaling\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m         \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 883\u001b[1;33m         sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    884\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    885\u001b[0m     \u001b[0mlog_reg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\sanjana\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mlogistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, copy, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight)\u001b[0m\n\u001b[0;32m    712\u001b[0m             coef_, intercept_, n_iter_i, = _fit_liblinear(\n\u001b[0;32m    713\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_intercept\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mintercept_scaling\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 714\u001b[1;33m                 penalty, dual, verbose, max_iter, tol, random_state)\n\u001b[0m\u001b[0;32m    715\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mfit_intercept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m                 \u001b[0mw0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mintercept_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\sanjana\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[1;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon)\u001b[0m\n\u001b[0;32m    878\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mloss_l\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'epsilon_insensitive'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'squared_epsilon_insensitive'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[0menc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0my_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\sanjana\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[0m_check_numpy_unicode_bug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\sanjana\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[0mar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m         \u001b[0maux\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mar\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m     \u001b[0mflag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maux\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0maux\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0moptional_returns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Logistic Regression : One Versus One\n",
    "# Use validation set to find which solver to use \n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "fold_results_ovo = pd.DataFrame()\n",
    "test_sets = []\n",
    "test_set_labels = []\n",
    "train_sets = []\n",
    "train_set_labels = []\n",
    "\n",
    "def ten_fold_oneVsRest_Perc(data, labels):\n",
    "    foldnum = 0\n",
    "    #solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "    \n",
    "    for train, test in cross_validation.KFold(len(data), n_folds=10, shuffle=True):\n",
    "        [tr_data, te_data,\n",
    "         tr_target, te_target] = folds_to_split(data, labels,train,test)\n",
    "        \n",
    "        train_sets.append(tr_data)\n",
    "        train_set_labels.append(tr_target)\n",
    "        test_sets.append(te_data)\n",
    "        test_set_labels.append(te_target)\n",
    "    \n",
    "    foldnum = 0\n",
    "    for x in range(0, 10):\n",
    "        foldnum+=1\n",
    "        [bnb_train, bnb_validation, bnb_train_labels, bnb_validation_labels] = cross_validation.train_test_split(\n",
    "        train_sets[x], \n",
    "        train_set_labels[x], \n",
    "        test_size=0.88, \n",
    "        random_state=20160121)\n",
    "        oneVsOne = OneVsRestClassifier(linear_model.Perceptron(penalty='l2'))\n",
    "        oneVsOne.fit(bnb_train.values, bnb_train_labels[bnb_train_labels.columns.values[0]].values)\n",
    "        \n",
    "        #perc.fit(heart_tr_data, heart_tr_target[0].values)\n",
    "        columnname = \"Accuracy\"\n",
    "        fold_results_ovo.loc[foldnum, columnname] = oneVsOne.score(bnb_validation, bnb_validation_labels)\n",
    "        #for sol in solvers:\n",
    "        \n",
    "        #predictions = oneVsOne.predict_proba(te_data)\n",
    "        #score = ndcg_score(te_target.as_matrix(), predictions, 5)\n",
    "        #fold_results_ovo.loc[foldnum, 'ndcg']  = score\n",
    "        #print(score)\n",
    "    \n",
    "    #Now let's look at the results:\n",
    "    print (\"-----------OneVsOneClassifier results for accuracy-----------\")\n",
    "    print (fold_results_ovo)\n",
    "    \n",
    "    print (\"--------------OneVsOneClassifier mean accuracy----------------\")\n",
    "    print(fold_results_ovo.mean())\n",
    "    \n",
    "ten_fold_oneVsRest_Perc(train_users, labels_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
