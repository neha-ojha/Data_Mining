{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      NDF\n",
      "1      NDF\n",
      "2       US\n",
      "3    other\n",
      "4       US\n",
      "Name: country_destination, dtype: object\n",
      "           id date_account_created  timestamp_first_active date_first_booking  \\\n",
      "0  gxn3p5htnn           2010-06-28          20090319043255                NaN   \n",
      "1  820tgsjxq7           2011-05-25          20090523174809                NaN   \n",
      "2  4ft3gnwmtx           2010-09-28          20090609231247         2010-08-02   \n",
      "3  bjjt8pjhuk           2011-12-05          20091031060129         2012-09-08   \n",
      "4  87mebub9p4           2010-09-14          20091208061105         2010-02-18   \n",
      "\n",
      "      gender  age signup_method  signup_flow language affiliate_channel  \\\n",
      "0  -unknown-  NaN      facebook            0       en            direct   \n",
      "1       MALE   38      facebook            0       en               seo   \n",
      "2     FEMALE   56         basic            3       en            direct   \n",
      "3     FEMALE   42      facebook            0       en            direct   \n",
      "4  -unknown-   41         basic            0       en            direct   \n",
      "\n",
      "  affiliate_provider first_affiliate_tracked signup_app first_device_type  \\\n",
      "0             direct               untracked        Web       Mac Desktop   \n",
      "1             google               untracked        Web       Mac Desktop   \n",
      "2             direct               untracked        Web   Windows Desktop   \n",
      "3             direct               untracked        Web       Mac Desktop   \n",
      "4             direct               untracked        Web       Mac Desktop   \n",
      "\n",
      "  first_browser  \n",
      "0        Chrome  \n",
      "1        Chrome  \n",
      "2            IE  \n",
      "3       Firefox  \n",
      "4        Chrome  \n"
     ]
    }
   ],
   "source": [
    "# Read the train and the test data \n",
    "train_users = pd.read_csv('train_users_2.csv')\n",
    "test_users = pd.read_csv('test_users.csv')\n",
    "\n",
    "\n",
    "# Extracting labels from the train data\n",
    "train_users_labels = train_users.loc[:,'country_destination']\n",
    "print (train_users_labels.head(n=5))\n",
    "\n",
    "# Extracting attributes from the train data\n",
    "train_users_attrs = train_users.iloc[:,0:15]\n",
    "print(train_users_attrs.head(n=5))\n",
    "\n",
    "train_users = train_users_attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_users = train_users.drop(['date_first_booking'], axis=1)\n",
    "test_users = test_users.drop(['date_first_booking'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Date is split into 3 parts as year, month and day in both test and train. These are added as\n",
    "# new features in both test and train\n",
    "\n",
    "date_acc_created = np.vstack(train_users.date_account_created.astype(str).apply(\n",
    "        lambda x: list(map(int, x.split('-')))).values)\n",
    "train_users['created_year'] = date_acc_created[:,0]\n",
    "train_users['created_month'] = date_acc_created[:,1]\n",
    "train_users['created_day'] = date_acc_created[:,2]\n",
    "train_users = train_users.drop(['date_account_created'], axis=1)\n",
    "\n",
    "date_acc_created_test = np.vstack(test_users.date_account_created.astype(str).apply(\n",
    "        lambda x: list(map(int, x.split('-')))).values)\n",
    "test_users['created_year'] = date_acc_created_test[:,0]\n",
    "test_users['created_month'] = date_acc_created_test[:,1]\n",
    "test_users['created_day'] = date_acc_created_test[:,2]\n",
    "test_users = test_users.drop(['date_account_created'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replacing unknown values in gender with -1 and null values with -1\n",
    "train_users.loc[ train_users['gender'] == '-unknown-', 'gender'] = -1\n",
    "train_users.loc[ train_users['gender'].isnull(), 'gender' ] = -1\n",
    "test_users.loc[ test_users['gender'] == '-unknown-', 'gender'] = -1\n",
    "test_users.loc[ test_users['gender'].isnull(), 'gender'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encoding Female with 0, Male with 1 and Other with 2 in both test and train data\n",
    "gender_translation = {'FEMALE' : 0,\n",
    "                     'MALE' : 1,\n",
    "                     'OTHER' : 2,\n",
    "                     -1 : -1 }\n",
    "for data in [train_users, test_users]:\n",
    "    data['gender'] = data['gender'].apply(lambda x: gender_translation[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing gender value distribution\n",
      "(0, ':', 0.5353209412124351)\n",
      "(1, ':', 0.46228441870536585)\n",
      "(2, ':', 0.002394640082198993)\n"
     ]
    }
   ],
   "source": [
    "# Finding valid values for gender and invalid values for gender\n",
    "nan_gender_count = len(train_users.loc[train_users['gender'] == -1, 'gender'])\n",
    "valid_gender_count = len(train_users.gender.values) - nan_gender_count\n",
    "\n",
    "# Creating a map with the gender distribution\n",
    "count_map = pd.value_counts(train_users['gender'].values)\n",
    "print (\"Existing gender value distribution\")\n",
    "for k, v in count_map.iteritems():\n",
    "    if k == -1:\n",
    "        continue\n",
    "    print (k, \":\", float(v)/float(valid_gender_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Making the gender distribution the same for missing imputation\n",
    "for k, v in count_map.iteritems():\n",
    "    if k == -1:\n",
    "        continue\n",
    "    c = int ( nan_gender_count * float(v)/float(valid_gender_count) )\n",
    "    for i in range(len(train_users.gender.values)):\n",
    "        if train_users.gender.values[i] == -1:\n",
    "            train_users.gender.values[i] = k\n",
    "            c -= 1\n",
    "        if c == 0:\n",
    "            break\n",
    "train_users.gender.values[213450] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    213451.000000\n",
       "mean          0.467072\n",
       "std           0.503691\n",
       "min           0.000000\n",
       "25%           0.000000\n",
       "50%           0.000000\n",
       "75%           1.000000\n",
       "max           2.000000\n",
       "Name: gender, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_users.gender.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing gender value distribution\n",
      "(0, ':', 0.5116944601469757)\n",
      "(1, ':', 0.486468343697004)\n",
      "(2, ':', 0.0018371961560203504)\n"
     ]
    }
   ],
   "source": [
    "nan_gender_count = len(test_users.loc[test_users['gender'] == -1, 'gender'])\n",
    "valid_gender_count = len(test_users.gender.values) - nan_gender_count\n",
    "count_map = pd.value_counts(test_users['gender'].values)\n",
    "print (\"Existing gender value distribution\")\n",
    "for k, v in count_map.iteritems():\n",
    "    if k == -1:\n",
    "        continue\n",
    "    print (k, \":\", float(v)/float(valid_gender_count))\n",
    "\n",
    "for k, v in count_map.iteritems():\n",
    "    if k == -1:\n",
    "        continue\n",
    "    c = int ( nan_gender_count * float(v)/float(valid_gender_count) )\n",
    "    for i in range(len(test_users.gender.values)):\n",
    "        if test_users.gender.values[i] == -1:\n",
    "            test_users.gender.values[i] = k\n",
    "            c -= 1\n",
    "        if c == 0:\n",
    "            break\n",
    "test_users.gender.values[62094] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    125461.000000\n",
       "mean         49.668335\n",
       "std         155.666612\n",
       "min           1.000000\n",
       "25%          28.000000\n",
       "50%          34.000000\n",
       "75%          43.000000\n",
       "max        2014.000000\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_users['age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replacing invalid age with NaN in test and train\n",
    "\n",
    "train_users.loc[train_users['age'] > 95, 'age'] = np.nan\n",
    "train_users.loc[train_users['age'] < 16, 'age'] = np.nan\n",
    "test_users.loc[test_users['age'] > 95, 'age'] = np.nan\n",
    "test_users.loc[test_users['age'] < 16, 'age'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.0\n",
      "31.0\n"
     ]
    }
   ],
   "source": [
    "# Replace missing age with median\n",
    "print (train_users.age.median())\n",
    "print (test_users.age.median())\n",
    "train_users.loc[ train_users['age'].isnull(), 'age' ] = train_users.age.median()\n",
    "test_users.loc[ test_users['age'].isnull(), 'age' ] = test_users.age.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Encoding the signup method for test\n",
    "signup_translation = {'facebook' : 0,\n",
    "                     'google' : 1,\n",
    "                     'basic' : 2,\n",
    "                     'weibo' : 3}\n",
    "for data in [train_users, test_users]:\n",
    "    data['signup_method'] = data['signup_method'].apply(lambda x: signup_translation[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Encoding the language in both train and test\n",
    "test_users.loc[ test_users['language'] == '-unknown-', 'language'] = \"en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "language_encoding = {'en'      :       1       ,\n",
    "'zh'      :       2       ,\n",
    "'fr'      :       3       ,\n",
    "'es'      :       4       ,\n",
    "'ko'      :       5       ,\n",
    "'de'      :       6       ,\n",
    "'it'      :       7       ,\n",
    "'ru'      :       8       ,\n",
    "'pt'      :       9       ,\n",
    "'ja'      :       10      ,\n",
    "'sv'      :       11      ,\n",
    "'nl'      :       12      ,\n",
    "'tr'      :       13      ,\n",
    "'da'      :       14      ,\n",
    "'pl'      :       15      ,\n",
    "'cs'      :       16      ,\n",
    "'no'      :       17      ,\n",
    "'el'      :       18      ,\n",
    "'th'      :       19      ,\n",
    "'id'      :       20      ,\n",
    "'hu'      :       21      ,\n",
    "'fi'      :       22      ,\n",
    "'ca'      :       23      ,\n",
    "'is'      :       24      ,\n",
    "'hr'      :       25}\n",
    "\n",
    "for data in [train_users, test_users]:\n",
    "    data['language'] = data['language'].apply(lambda x: language_encoding[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "affiliate_channel_encoding = {'direct' : 1,\n",
    "                             'sem-brand' : 2,\n",
    "                             'sem-non-brand' : 3,\n",
    "                             'other' : 4,\n",
    "                             'api' : 5,\n",
    "                             'seo' : 6,\n",
    "                             'content' : 7,\n",
    "                             'remarketing' : 8}\n",
    "for data in [train_users, test_users]:\n",
    "    data['affiliate_channel'] = data['affiliate_channel'].apply(lambda x: affiliate_channel_encoding[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "affiliate_provider_encoding = {'direct':1,\n",
    "'google':2,\n",
    "'other':3,\n",
    "'craigslist':4,\n",
    "'bing':5,\n",
    "'facebook':6,\n",
    "'vast':7,\n",
    "'padmapper':8,\n",
    "'facebook-open-graph':9,\n",
    "'yahoo':10,\n",
    "'gsp':11,\n",
    "'meetup':12,\n",
    "'email-marketing':13,\n",
    "'naver':14,\n",
    "'baidu':15,\n",
    "'yandex':16,\n",
    "'wayn':17,\n",
    "'daum':18}\n",
    "\n",
    "for data in [train_users, test_users]:\n",
    "    data['affiliate_provider'] = data['affiliate_provider'].apply(lambda x: affiliate_provider_encoding[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_users.loc[ train_users['first_affiliate_tracked'].isnull(), 'first_affiliate_tracked'] = \"untracked\"\n",
    "test_users.loc[ test_users['first_affiliate_tracked'].isnull(), 'first_affiliate_tracked'] = \"untracked\"\n",
    "first_affiliate_tracked_encoding = {'untracked' : 1,\n",
    "                                   'linked' : 2,\n",
    "                                   'omg' : 3,\n",
    "                                   'tracked-other' : 4,\n",
    "                                   'product' : 5,\n",
    "                                   'marketing' : 6,\n",
    "                                   'local ops' : 7}\n",
    "for data in [train_users, test_users]:\n",
    "    data['first_affiliate_tracked'] = data['first_affiliate_tracked'].apply(lambda x: first_affiliate_tracked_encoding[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "signup_app_encoding = {'Web' : 1,\n",
    "                      'iOS' : 2,\n",
    "                      'Android' : 3,\n",
    "                      'Moweb' : 4}\n",
    "for data in [train_users, test_users]:\n",
    "    data['signup_app'] = data['signup_app'].apply(lambda x: signup_app_encoding[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "first_device_type_encoding = { 'Mac Desktop' : 1,\n",
    "                             'iPhone' : 2,\n",
    "                             'Windows Desktop' : 3,\n",
    "                             'Android Phone' : 4,\n",
    "                             'iPad' : 5,\n",
    "                             'Android Tablet' : 6,\n",
    "                             'Other/Unknown' : 7,\n",
    "                             'Desktop (Other)' : 8,\n",
    "                             'SmartPhone (Other)' : 9}\n",
    "for data in [train_users, test_users]:\n",
    "    data['first_device_type'] = data['first_device_type'].apply(lambda x: first_device_type_encoding[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "first_browser_encoding = {'Chrome':1,\n",
    "'Safari':2,\n",
    "'Firefox':3,\n",
    "'-unknown-':4,\n",
    "'IE':5,\n",
    "'Mobile Safari':6,\n",
    "'Chrome Mobile':7,\n",
    "'Android Browser':8,\n",
    "'AOL Explorer':9,\n",
    "'Opera':10,\n",
    "'Silk':11,\n",
    "'Chromium':12,\n",
    "'BlackBerry Browser':13,\n",
    "'Maxthon':14,\n",
    "'IE Mobile':15,\n",
    "'Apple Mail':16,\n",
    "'Sogou Explorer':17,\n",
    "'Mobile Firefox':18,\n",
    "'RockMelt':19,\n",
    "'SiteKiosk':20,\n",
    "'Iron':21,\n",
    "'IceWeasel':22,\n",
    "'Pale Moon':23,\n",
    "'SeaMonkey':24,\n",
    "'Yandex.Browser':25,\n",
    "'CometBird':26,\n",
    "'Camino':27,\n",
    "'TenFourFox':28,\n",
    "'wOSBrowser':29,\n",
    "'CoolNovo':30,\n",
    "'Avant Browser':31,\n",
    "'Opera Mini':32,\n",
    "'Mozilla':33,\n",
    "'Comodo Dragon':34,\n",
    "'TheWorld Browser':35,\n",
    "'Crazy Browser':36,\n",
    "'Flock':37,\n",
    "'OmniWeb':38,\n",
    "'SlimBrowser':39,\n",
    "'Opera Mobile':40,\n",
    "'Conkeror':41,\n",
    "'Outlook 2007':42,\n",
    "'Palm Pre web browser':43,\n",
    "'Stainless':44,\n",
    "'NetNewsWire':45,\n",
    "'Kindle Browser':46,\n",
    "'Epic':47,\n",
    "'Googlebot':48,\n",
    "'Arora':49,\n",
    "'Google Earth':50,\n",
    "'IceDragon':51,\n",
    "'PS Vita browser':52,\n",
    "'IBrowse' : 53,\n",
    "'UC Browser' : 54,\n",
    "'IBrowse': 55,\n",
    "'Nintendo Browser' : 56}\n",
    "\n",
    "\n",
    "for data in [train_users, test_users]:\n",
    "    data['first_browser'] = data['first_browser'].apply(lambda x: first_browser_encoding[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sessions = pd.read_csv('sessions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(135483,)\n",
      "mxqbh3ykxl    2722\n",
      "0hjoc5q8nf    2644\n",
      "mjbl6rrj52    2476\n",
      "l5lgm3w5pc    2424\n",
      "wg9413iaux    2362\n",
      "ht8alhs4lt    2335\n",
      "wyv1imf8qw    2323\n",
      "monrpvx2md    2264\n",
      "9z4gim1s4l    2264\n",
      "h0cjxc177k    2246\n",
      "a0uhiojrra    2137\n",
      "vcmr2jh5ix    2085\n",
      "1m6xnhstmb    2019\n",
      "p1183hxzc4    1938\n",
      "e8h4qghxlg    1923\n",
      "gey51ednme    1919\n",
      "5vpuk5mssg    1876\n",
      "j2cvctvqve    1861\n",
      "yu5bdalz2b    1811\n",
      "ejpe95pcyo    1797\n",
      "r541x78s24    1792\n",
      "qkbkunyzq7    1780\n",
      "n4s6g3grzf    1779\n",
      "bfiueza7rt    1753\n",
      "b1io359wpg    1752\n",
      "8ikl7vnfa3    1732\n",
      "e81qfos71y    1701\n",
      "s5ez13snz0    1685\n",
      "93dulcecw0    1614\n",
      "r0rgjqbsvp    1612\n",
      "              ... \n",
      "vlji8fg52x       1\n",
      "4s2v2hmngj       1\n",
      "n2rrpf1t3h       1\n",
      "ua4bebdziw       1\n",
      "gks02el96u       1\n",
      "e7l7yocdtk       1\n",
      "ztvrwgyxm2       1\n",
      "w5sn4qqiav       1\n",
      "9o5gi1x2i4       1\n",
      "kl81vani0y       1\n",
      "1uaksuktr5       1\n",
      "c9vanbl9nh       1\n",
      "n6tcyc7thd       1\n",
      "cgdsmvs4sw       1\n",
      "f9ohif5u6w       1\n",
      "wiru94r12h       1\n",
      "l28osl4y6x       1\n",
      "t9o5rwmg1k       1\n",
      "hjhljq8k89       1\n",
      "ah2mvtfp74       1\n",
      "q7xk33e009       1\n",
      "d8rix1ykp3       1\n",
      "b36nw4lraq       1\n",
      "ub3ssm8b09       1\n",
      "jawie8g9tj       1\n",
      "6kvyu52h3f       1\n",
      "a8kcc3pxp9       1\n",
      "p8ep74z8i4       1\n",
      "9w94dnnpsi       1\n",
      "ov4eqxdx3s       1\n",
      "Name: user_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# frequency of each user_id in sessions data\n",
    "df = sessions['user_id'].value_counts()\n",
    "print (df.shape)\n",
    "print (df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Updating session_count for users present in the train data\n",
    "\n",
    "train_users['session_count'] = 0\n",
    "\n",
    "for key,val in df.iteritems():\n",
    "    train_users.loc[train_users[ 'id' ] == key, 'session_count'] = val\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2644\n"
     ]
    }
   ],
   "source": [
    "print (train_users['session_count'].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#train_users_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "country_destination_encoding = {'NDF': 0,\n",
    "'US' : 1,\n",
    "'other' : 2,\n",
    "'FR' : 3,\n",
    "'IT' : 4,\n",
    "'GB' : 5,\n",
    "'ES' : 6,\n",
    "'CA' : 7,\n",
    "'DE' : 8,\n",
    "'NL' : 9,\n",
    "'AU' : 10,\n",
    "'PT' : 11}\n",
    "\n",
    "# Convert series to frame\n",
    "labels_df = train_users_labels.to_frame()\n",
    "\n",
    "for data in [labels_df]:\n",
    "    data['country_destination'] = data['country_destination'].apply(lambda x: country_destination_encoding[x])\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def folds_to_split(data,targets,train,test):\n",
    "    data_tr = pd.DataFrame(data).iloc[train]\n",
    "    data_te = pd.DataFrame(data).iloc[test]\n",
    "    labels_tr = pd.DataFrame(targets).iloc[train]\n",
    "    labels_te = pd.DataFrame(targets).iloc[test]\n",
    "    return [data_tr, data_te, labels_tr, labels_te]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make_scorer(ndcg_score, needs_proba=True, k=5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def dcg_score(y_true, y_score, k=5):\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order[:k])\n",
    "\n",
    "    gain = 2 ** y_true - 1\n",
    "\n",
    "    discounts = np.log2(np.arange(len(y_true)) + 2)\n",
    "    return np.sum(gain / discounts)\n",
    "\n",
    "\n",
    "#def ndcg_score(ground_truth, predictions, k=5):\n",
    "def ndcg_score(te_labels, predict, k):\n",
    "    \n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(range(len(predict) + 1))\n",
    "    T = lb.transform(te_labels)\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    # Iterate over each y_true and compute the DCG score\n",
    "    for y_true, y_score in zip(T, predict):\n",
    "        actual = dcg_score(y_true, y_score, k)\n",
    "        best = dcg_score(y_true, y_true, k)\n",
    "        if best == 0:\n",
    "            best = 0.000000001\n",
    "        score = float(actual) / float(best)\n",
    "        scores.append(score)\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "# NDCG Scorer function\n",
    "ndcg_scorer = make_scorer(ndcg_score, needs_proba=True, k=5)\n",
    "print ndcg_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id  timestamp_first_active  gender  age  signup_method  \\\n",
      "0  gxn3p5htnn          20090319043255       0   34              0   \n",
      "1  820tgsjxq7          20090523174809       1   38              0   \n",
      "2  4ft3gnwmtx          20090609231247       0   56              2   \n",
      "3  bjjt8pjhuk          20091031060129       0   42              0   \n",
      "4  87mebub9p4          20091208061105       0   41              2   \n",
      "\n",
      "   signup_flow  language  affiliate_channel  affiliate_provider  \\\n",
      "0            0         1                  1                   1   \n",
      "1            0         1                  6                   2   \n",
      "2            3         1                  1                   1   \n",
      "3            0         1                  1                   1   \n",
      "4            0         1                  1                   1   \n",
      "\n",
      "   first_affiliate_tracked  signup_app  first_device_type  first_browser  \\\n",
      "0                        1           1                  1              1   \n",
      "1                        1           1                  1              1   \n",
      "2                        1           1                  3              5   \n",
      "3                        1           1                  1              3   \n",
      "4                        1           1                  1              1   \n",
      "\n",
      "   created_year  created_month  created_day  session_count  \n",
      "0          2010              6           28              0  \n",
      "1          2011              5           25              0  \n",
      "2          2010              9           28              0  \n",
      "3          2011             12            5              0  \n",
      "4          2010              9           14              0  \n",
      "   timestamp_first_active  gender  age  signup_method  signup_flow  language  \\\n",
      "0          20090319043255       0   34              0            0         1   \n",
      "1          20090523174809       1   38              0            0         1   \n",
      "2          20090609231247       0   56              2            3         1   \n",
      "3          20091031060129       0   42              0            0         1   \n",
      "4          20091208061105       0   41              2            0         1   \n",
      "\n",
      "   affiliate_channel  affiliate_provider  first_affiliate_tracked  signup_app  \\\n",
      "0                  1                   1                        1           1   \n",
      "1                  6                   2                        1           1   \n",
      "2                  1                   1                        1           1   \n",
      "3                  1                   1                        1           1   \n",
      "4                  1                   1                        1           1   \n",
      "\n",
      "   first_device_type  first_browser  created_year  created_month  created_day  \\\n",
      "0                  1              1          2010              6           28   \n",
      "1                  1              1          2011              5           25   \n",
      "2                  3              5          2010              9           28   \n",
      "3                  1              3          2011             12            5   \n",
      "4                  1              1          2010              9           14   \n",
      "\n",
      "   session_count  \n",
      "0              0  \n",
      "1              0  \n",
      "2              0  \n",
      "3              0  \n",
      "4              0  \n"
     ]
    }
   ],
   "source": [
    "print train_users.head()\n",
    "train_users=train_users.drop(['id'], axis=1)\n",
    "print train_users.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import preprocessing, cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth:1\n",
      "NDCG Score : 0.820989\n",
      "Depth:2\n",
      "NDCG Score : 0.824146\n",
      "Depth:3\n",
      "NDCG Score : 0.824480\n",
      "Depth:4\n",
      "NDCG Score : 0.824219\n",
      "Depth:5\n",
      "NDCG Score : 0.823509\n"
     ]
    }
   ],
   "source": [
    "# Gradient boosting with test train split varying max_depth\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "foldnum = 0\n",
    "fold_results = pd.DataFrame()\n",
    "depth_list = [1, 2, 3, 4, 5]\n",
    "[tr_data, te_data, tr_labels, te_labels] = cross_validation.train_test_split(train_users, labels_df, test_size=0.33,\n",
    "                                                                             random_state=20160302)\n",
    "for depth in depth_list:\n",
    "    gb_clf = GradientBoostingClassifier(max_depth=depth, n_estimators=100, random_state=20160302)\n",
    "    gb_clf.fit(tr_data, tr_labels.values.ravel())\n",
    "    prob_arr_gb = gb_clf.predict_proba(te_data)\n",
    "    #ground_truth = te_labels.as_matrix()\n",
    "    #fold_results.loc[foldnum, 'Accuracy'] = gnb.score(te_data,te_labels)\n",
    "    score_gb = ndcg_score(te_labels.as_matrix(), prob_arr_gb, k=5)\n",
    "    print \"Depth:%d\" %depth\n",
    "    print \"NDCG Score : %f\" %score_gb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Estimators:100\n",
      "NDCG Score : 0.824480\n",
      "Num of Estimators:200\n",
      "NDCG Score : 0.824339\n",
      "Num of Estimators:300\n",
      "NDCG Score : 0.824018\n",
      "Num of Estimators:400\n",
      "NDCG Score : 0.823865\n",
      "Num of Estimators:500\n",
      "NDCG Score : 0.823780\n"
     ]
    }
   ],
   "source": [
    "# Gradient boosting with test train split varying num of estimators\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "foldnum = 0\n",
    "fold_results = pd.DataFrame()\n",
    "est_list = [100, 200, 300, 400, 500]\n",
    "[tr_data, te_data, tr_labels, te_labels] = cross_validation.train_test_split(train_users, labels_df, test_size=0.33,\n",
    "                                                                             random_state=20160302)\n",
    "for est in est_list :\n",
    "    gb_clf = GradientBoostingClassifier(max_depth=3, n_estimators=est, random_state=20160302)\n",
    "    gb_clf.fit(tr_data, tr_labels.values.ravel())\n",
    "    prob_arr_gb = gb_clf.predict_proba(te_data)\n",
    "    #ground_truth = te_labels.as_matrix()\n",
    "    #fold_results.loc[foldnum, 'Accuracy'] = gnb.score(te_data,te_labels)\n",
    "    score_gb = ndcg_score(te_labels.as_matrix(), prob_arr_gb, k=5)\n",
    "    print \"Num of Estimators:%d\" %est\n",
    "    print \"NDCG Score : %f\" %score_gb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Observations\n",
    "\n",
    "The above analysis done by varying a) the max_depth and b) the number of estimators for Gradinet Boosting Classifier. As we can notice from the above results, we get the highest NDCG score for max_depth = 3 and this parameter is used to do the analysis for number of estimarors. The next analysis shows that the highest score is achieved with number of estimators = 300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
